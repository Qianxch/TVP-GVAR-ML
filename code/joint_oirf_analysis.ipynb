{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4a8eea-252e-4c77-bd54-9105e22f7c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.linalg import inv, eigvals, cholesky\n",
    "from statsmodels.tsa.stattools import acf\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "PAPER_RC = {\n",
    "    \"font.sans-serif\": [\"Times New Roman\"],\n",
    "    \"axes.unicode_minus\": False,\n",
    "    \"font.size\": 11,\n",
    "    \"axes.titlesize\": 13,\n",
    "    \"figure.titlesize\": 15,\n",
    "    \"legend.fontsize\": 10,\n",
    "    \"xtick.labelsize\": 10,\n",
    "    \"ytick.labelsize\": 10,\n",
    "    \"axes.spines.top\": False,\n",
    "    \"axes.spines.right\": False,\n",
    "    \"savefig.bbox\": \"tight\",\n",
    "    \"savefig.dpi\": 300,\n",
    "}\n",
    "mpl.rcParams.update(PAPER_RC)\n",
    "mpl.rcParams[\"pdf.fonttype\"] = 42\n",
    "mpl.rcParams[\"ps.fonttype\"] = 42\n",
    "\n",
    "BLUE = \"#1f77b4\"\n",
    "ORANGE = \"#d95f02\"\n",
    "GRAY = \"#bdbdbd\"\n",
    "\n",
    "LW_MEAN = 2.0\n",
    "LW_BAND = 1.3\n",
    "LW_ZERO = 1.0\n",
    "\n",
    "def fmt_var(name: str) -> str:\n",
    "    if \"_\" not in name:\n",
    "        return name\n",
    "    a, b = name.split(\"_\", 1)\n",
    "    return f\"{a}({b})\"\n",
    "\n",
    "def fmt_combo(names):\n",
    "    return \", \".join(fmt_var(n) for n in names)\n",
    "\n",
    "def choose_block_len(residuals, max_lag: int = 12) -> int:\n",
    "    acf_vals = acf(residuals, nlags=max_lag)\n",
    "    for lag in range(1, max_lag + 1):\n",
    "        if abs(acf_vals[lag]) < 0.2:\n",
    "            return lag\n",
    "    return max_lag\n",
    "\n",
    "def mbb_resample(e_arr, block_len, T_res):\n",
    "    num_blocks = int(np.ceil(T_res / block_len))\n",
    "    max_start = T_res - block_len\n",
    "    blocks = [e_arr[random.randint(0, max_start) : ][:block_len] for _ in range(num_blocks)]\n",
    "    return np.vstack(blocks)[:T_res]\n",
    "\n",
    "def load_data(path, split_date: str = \"2023-06-01\"):\n",
    "    df = (\n",
    "        pd.read_excel(path, parse_dates=[\"Date\"])\n",
    "        .set_index(\"Date\")\n",
    "        .sort_index()\n",
    "        .ffill()\n",
    "    )\n",
    "    train, test = df.loc[:split_date], df.loc[split_date:]\n",
    "    return df, train, test\n",
    "\n",
    "CPI_IDX, HUR_IDX, GDP_IDX, WTI_IDX = [0, 1, 2], [3, 4, 5], [6, 7, 8], [9]\n",
    "\n",
    "def make_weights():\n",
    "    W = np.array(\n",
    "        [\n",
    "            [0.0, 0.137, 0.15],\n",
    "            [0.45, 0.0, 0.85],\n",
    "            [0.55, 0.863, 0.0],\n",
    "        ],\n",
    "        dtype=float,\n",
    "    )\n",
    "    np.fill_diagonal(W, 0.0)\n",
    "    col_sum = W.sum(axis=0, keepdims=True)\n",
    "    col_sum[col_sum == 0] = 1.0\n",
    "    W = W / col_sum\n",
    "    return W\n",
    "\n",
    "def make_gvar_mask():\n",
    "    M = np.zeros((10, 10))\n",
    "    for grp in [CPI_IDX, HUR_IDX, GDP_IDX]:\n",
    "        for r in grp:\n",
    "            M[r, grp] = 1\n",
    "            M[r, WTI_IDX] = 1\n",
    "    M[9, 9] = 1\n",
    "    return M\n",
    "\n",
    "W_E = make_weights()\n",
    "GVAR_MASK = make_gvar_mask()\n",
    "\n",
    "# -------- constant GVAR --------\n",
    "def fit_const_gvar(df_train, var_list, force_stable: bool = True, shrink: float = 0.98):\n",
    "    X = df_train[var_list].values\n",
    "    T, n = X.shape\n",
    "\n",
    "    def foreign(x):\n",
    "        out = np.zeros_like(x)\n",
    "        out[CPI_IDX] = W_E @ x[CPI_IDX]\n",
    "        out[HUR_IDX] = W_E @ x[HUR_IDX]\n",
    "        out[GDP_IDX] = W_E @ x[GDP_IDX]\n",
    "        return out\n",
    "\n",
    "    Z = np.vstack([foreign(X[t - 1]) for t in range(1, T)])\n",
    "    Y = X[1:]\n",
    "\n",
    "    b = np.zeros(n)\n",
    "    F = np.zeros((n, n))\n",
    "\n",
    "    for i in range(n):\n",
    "        mask = GVAR_MASK[i].astype(bool)\n",
    "        Xi = np.column_stack([np.ones(T - 1), Z[:, mask]])\n",
    "        beta, *_ = np.linalg.lstsq(Xi, Y[:, i], rcond=None)\n",
    "        b[i] = beta[0]\n",
    "        F[i, mask] = beta[1:]\n",
    "\n",
    "    if force_stable:\n",
    "        rho = np.abs(eigvals(F)).max()\n",
    "        if rho >= 1:\n",
    "            F *= shrink / rho\n",
    "\n",
    "    return b, F\n",
    "\n",
    "# -------- TVP-GVAR (Kalman) --------\n",
    "def fit_tvp_gvar(df, Q_b: float = 0.001, Q_f: float = 0.0005):\n",
    "    var_list = df.columns.tolist()\n",
    "    X = df.values\n",
    "    T, n = X.shape\n",
    "    dim = n + n * n\n",
    "\n",
    "    theta = np.zeros(dim)\n",
    "    P = np.eye(dim)\n",
    "    Q = np.diag(np.r_[np.full(n, Q_b), np.full(n * n, Q_f)])\n",
    "    R = np.eye(n)\n",
    "\n",
    "    traj = np.zeros((T, dim))\n",
    "\n",
    "    def foreign(x):\n",
    "        out = np.zeros_like(x)\n",
    "        out[CPI_IDX] = W_E @ x[CPI_IDX]\n",
    "        out[HUR_IDX] = W_E @ x[HUR_IDX]\n",
    "        out[GDP_IDX] = W_E @ x[GDP_IDX]\n",
    "        return out\n",
    "\n",
    "    for t in range(1, T):\n",
    "        xp, xn = X[t - 1], X[t]\n",
    "        z_prev = foreign(xp)\n",
    "\n",
    "        H = np.zeros((n, dim))\n",
    "        H[:, :n] = np.eye(n)\n",
    "        for i in range(n):\n",
    "            masked = z_prev * GVAR_MASK[i]\n",
    "            H[i, n + i * n : n + (i + 1) * n] = masked\n",
    "\n",
    "        theta_pred = theta\n",
    "        P_pred = P + Q\n",
    "        v = xn - H @ theta_pred\n",
    "        S = H @ P_pred @ H.T + R\n",
    "        K = P_pred @ H.T @ inv(S)\n",
    "        theta = theta_pred + K @ v\n",
    "        P = (np.eye(dim) - K @ H) @ P_pred\n",
    "\n",
    "        b = theta[:n]\n",
    "        F = theta[n:].reshape(n, n)\n",
    "        rho = np.abs(eigvals(F)).max()\n",
    "        if rho >= 1:\n",
    "            F *= 0.98 / rho\n",
    "        F *= GVAR_MASK\n",
    "        theta = np.r_[b, F.flatten()]\n",
    "\n",
    "        traj[t] = theta\n",
    "\n",
    "    return traj, var_list\n",
    "\n",
    "# -------- IRF computation --------\n",
    "def irf_path(F, shock_vec, horizon: int = 8):\n",
    "    n = F.shape[0]\n",
    "    out = np.zeros((horizon + 1, n))\n",
    "    out[0] = shock_vec\n",
    "    for h in range(1, horizon + 1):\n",
    "        out[h] = F @ out[h - 1]\n",
    "    return out\n",
    "\n",
    "def combo_vec(chol, names, var_list):\n",
    "    n = len(var_list)\n",
    "    v = np.zeros(n)\n",
    "    for nm in names:\n",
    "        j = var_list.index(nm)\n",
    "        col = chol[:, j]\n",
    "        norm = np.linalg.norm(col)\n",
    "        if norm > 0:\n",
    "            v += col / norm\n",
    "    return v\n",
    "\n",
    "def joint_irf(\n",
    "    F, b, errs, var_list,\n",
    "    shock_combo, target_var,\n",
    "    horizon: int = 8,\n",
    "    n_sims: int = 300,\n",
    "    max_lag: int = 12,\n",
    "):\n",
    "    T_res = len(errs)\n",
    "    n = len(var_list)\n",
    "    blk = choose_block_len(errs.ravel(), max_lag)\n",
    "\n",
    "    Sig = errs.T @ errs / max(T_res - 1, 1) + 1e-6 * np.eye(n)\n",
    "    chol = cholesky(Sig)\n",
    "\n",
    "    v0 = combo_vec(chol, shock_combo, var_list)\n",
    "    mu_full = irf_path(F, v0, horizon)\n",
    "\n",
    "    sims = np.zeros((n_sims, horizon + 1, n))\n",
    "    for s in range(n_sims):\n",
    "        e_bs = mbb_resample(errs, blk, T_res)\n",
    "        Sig_b = e_bs.T @ e_bs / max(T_res - 1, 1) + 1e-6 * np.eye(n)\n",
    "        chol_b = cholesky(Sig_b)\n",
    "        v_b = combo_vec(chol_b, shock_combo, var_list)\n",
    "        sims[s] = irf_path(F, v_b, horizon)\n",
    "\n",
    "    lo = np.percentile(sims, 2.5, axis=0)\n",
    "    hi = np.percentile(sims, 97.5, axis=0)\n",
    "\n",
    "    j = var_list.index(target_var)\n",
    "    tgrid = np.arange(horizon + 1)\n",
    "    return tgrid, lo[:, j], hi[:, j], mu_full[:, j]\n",
    "\n",
    "def plot_joint_irf_grid(\n",
    "    traj,\n",
    "    var_list,\n",
    "    df_train,\n",
    "    shock_combo,\n",
    "    target_var,\n",
    "    pdf_path,\n",
    "    group_index: int,\n",
    "    horizon: int = 8,\n",
    "    n_sims: int = 300,\n",
    "    max_lag: int = 12,\n",
    "):\n",
    "    X = df_train[var_list].values\n",
    "    n = len(var_list)\n",
    "\n",
    "    b_c, F_c = fit_const_gvar(df_train, var_list)\n",
    "    errs_c = np.array([X[t] - (b_c + F_c @ X[t - 1]) for t in range(1, len(X))])\n",
    "\n",
    "    dates = [\"2020-06-01\", \"2013-04-01\", \"2007-12-01\"]\n",
    "    idx = [df_train.index.get_loc(d) for d in dates]\n",
    "\n",
    "    def get_tvp(idx_val):\n",
    "        b = traj[idx_val, :n]\n",
    "        F = traj[idx_val, n:].reshape(n, n)\n",
    "        e = np.array([X[t] - (b + F @ X[t - 1]) for t in range(1, len(X))])\n",
    "        return b, F, e\n",
    "\n",
    "    b20, F20, e20 = get_tvp(idx[0])\n",
    "    b13, F13, e13 = get_tvp(idx[1])\n",
    "    b07, F07, e07 = get_tvp(idx[2])\n",
    "\n",
    "    t_c, lo_c, hi_c, mu_c = joint_irf(F_c, b_c, errs_c, var_list, shock_combo, target_var, horizon, n_sims, max_lag)\n",
    "    t20, lo20, hi20, mu20 = joint_irf(F20, b20, e20, var_list, shock_combo, target_var, horizon, n_sims, max_lag)\n",
    "    t13, lo13, hi13, mu13 = joint_irf(F13, b13, e13, var_list, shock_combo, target_var, horizon, n_sims, max_lag)\n",
    "    t07, lo07, hi07, mu07 = joint_irf(F07, b07, e07, var_list, shock_combo, target_var, horizon, n_sims, max_lag)\n",
    "\n",
    "    Y = np.concatenate([lo_c, hi_c, lo20, hi20, lo13, hi13, lo07, hi07])\n",
    "    pad = 0.10 * (Y.max() - Y.min())\n",
    "    y_lim = (Y.min() - pad, Y.max() + pad)\n",
    "\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(12, 8), sharex=True, sharey=True)\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    def draw(ax, t, lo, hi, mu):\n",
    "        ax.fill_between(t, lo, hi, color=GRAY, alpha=0.33)\n",
    "        ax.plot(t, lo, \"--\", color=BLUE, lw=LW_BAND)\n",
    "        ax.plot(t, hi, \"--\", color=BLUE, lw=LW_BAND)\n",
    "        ax.plot(t, mu, \"-\", color=BLUE, lw=LW_MEAN)\n",
    "        ax.axhline(0, color=ORANGE, lw=LW_ZERO)\n",
    "        ax.set_ylim(*y_lim)\n",
    "\n",
    "    draw(axes[0], t_c, lo_c, hi_c, mu_c)\n",
    "    draw(axes[1], t20, lo20, hi20, mu20)\n",
    "    draw(axes[2], t13, lo13, hi13, mu13)\n",
    "    draw(axes[3], t07, lo07, hi07, mu07)\n",
    "\n",
    "    for ax in axes[2:4]:\n",
    "        ax.set_xlabel(\"Horizon\")\n",
    "    for ax in (axes[0], axes[2]):\n",
    "        ax.set_ylabel(\"Response\")\n",
    "\n",
    "    centers = []\n",
    "    for ax in axes:\n",
    "        pos = ax.get_position()\n",
    "        xc = pos.x0 + pos.width / 2\n",
    "        xc += 0.02\n",
    "        centers.append(xc)\n",
    "\n",
    "    labels = {1: [\"(a1)\", \"(b1)\", \"(c1)\", \"(d1)\"], 2: [\"(a2)\", \"(b2)\", \"(c2)\", \"(d2)\"]}[group_index]\n",
    "    main_titles = [\n",
    "        \"The time-invariant OIRF\",\n",
    "        \"The time-varying OIRF of June 1st, 2020\",\n",
    "        \"The time-varying OIRF of April 1st, 2013\",\n",
    "        \"The time-varying OIRF of December 1st, 2007\",\n",
    "    ]\n",
    "    combo = f\"{fmt_combo(shock_combo)} -> {fmt_var(target_var)}\"\n",
    "\n",
    "    Y1, Y2, Y3, Y4 = 0.92, 0.88, 0.48, 0.44\n",
    "\n",
    "    fig.text(centers[0], Y1, f\"{labels[0]} {main_titles[0]}\", ha=\"center\", fontsize=16)\n",
    "    fig.text(centers[1], Y1, f\"{labels[1]} {main_titles[1]}\", ha=\"center\", fontsize=16)\n",
    "    fig.text(centers[0], Y2, combo, ha=\"center\", fontsize=14)\n",
    "    fig.text(centers[1], Y2, combo, ha=\"center\", fontsize=14)\n",
    "\n",
    "    fig.text(centers[2], Y3, f\"{labels[2]} {main_titles[2]}\", ha=\"center\", fontsize=16)\n",
    "    fig.text(centers[3], Y3, f\"{labels[3]} {main_titles[3]}\", ha=\"center\", fontsize=16)\n",
    "    fig.text(centers[2], Y4, combo, ha=\"center\", fontsize=14)\n",
    "    fig.text(centers[3], Y4, combo, ha=\"center\", fontsize=14)\n",
    "\n",
    "    plt.subplots_adjust(hspace=0.40)\n",
    "\n",
    "    fig.savefig(pdf_path, dpi=300)\n",
    "    plt.show()\n",
    "    print(f\"[Saved] {pdf_path}\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    out_dir = \"../results\"\n",
    "    if not os.path.exists(out_dir):\n",
    "        os.makedirs(out_dir)\n",
    "        \n",
    "    file_path = \"../data/macro_panel.xlsx\"\n",
    "\n",
    "    df, train, _ = load_data(file_path, split_date=\"2024-01-01\")\n",
    "    traj, var_list = fit_tvp_gvar(train)\n",
    "\n",
    "    shocks_1 = [\"JP_HUR\", \"US_HUR\", \"EU_GDP\", \"WTI\"]\n",
    "    target_1 = \"US_GDP\"\n",
    "    pdf_A = os.path.join(out_dir, \"Joint_OIRF_Group1.pdf\")\n",
    "    plot_joint_irf_grid(traj, var_list, train, shocks_1, target_1, pdf_A, group_index=1)\n",
    "\n",
    "    shocks_2 = [\"EU_GDP\", \"US_GDP\"]\n",
    "    target_2 = \"US_CPI\"\n",
    "    pdf_B = os.path.join(out_dir, \"Joint_OIRF_Group2.pdf\")\n",
    "    plot_joint_irf_grid(traj, var_list, train, shocks_2, target_2, pdf_B, group_index=2)\n",
    "\n",
    "    print(\"=== ALL DONE ===\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
